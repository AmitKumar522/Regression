# ğŸ“˜ Regression Assignment â€“ Python + ML

This repository contains theory and practical examples for **Simple Linear Regression**, **Multiple Linear Regression**, and **Polynomial Regression** as part of the assignment from **Java + DSAPwskills**.

---

## ğŸ“Œ Topics Covered

### ğŸ”¹ Simple Linear Regression
- âœ… What is Simple Linear Regression?
- âœ… Key Assumptions
- âœ… Equation: **Y = mX + c**
- âœ… Slope (m) and Intercept (c) calculation
- âœ… Least Squares Method
- âœ… RÂ² Interpretation

### ğŸ”¹ Multiple Linear Regression
- âœ… Concept and Difference from Simple Linear Regression
- âœ… Key Assumptions
- âœ… Heteroscedasticity
- âœ… Multicollinearity handling
- âœ… Interaction Terms
- âœ… Categorical Variables Encoding

### ğŸ”¹ Regression Metrics
- âœ… Coefficient Significance
- âœ… Standard Error
- âœ… Adjusted RÂ²
- âœ… RÂ² Limitations

### ğŸ”¹ Polynomial Regression
- âœ… Use Case
- âœ… General Equation
- âœ… Differences from Linear Regression
- âœ… Model Selection Criteria (AIC, BIC, Cross-validation)
- âœ… Python Implementation

---

## ğŸ§  Sample Python Code

### â–¶ï¸ Polynomial Regression Example

```python
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
import numpy as np
import matplotlib.pyplot as plt

# Sample data
X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)
y = np.array([1, 4, 9, 16, 25])

# Create a model
model = make_pipeline(PolynomialFeatures(2), LinearRegression())
model.fit(X, y)

# Predictions
X_test = np.linspace(1, 5, 100).reshape(-1, 1)
y_pred = model.predict(X_test)

# Plot
plt.scatter(X, y, color='red', label='Actual')
plt.plot(X_test, y_pred, color='blue', label='Prediction')
plt.title("Polynomial Regression (Degree 2)")
plt.xlabel("X")
plt.ylabel("Y")
plt.legend()
plt.grid(True)
plt.show()
